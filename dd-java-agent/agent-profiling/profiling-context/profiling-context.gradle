plugins {
  id "me.champeau.jmh"
}

apply from: "$rootDir/gradle/java.gradle"
apply plugin: 'idea'

ext {
  minimumBranchCoverage = 0.6
  minimumInstructionCoverage = 0.8
  excludedClassesCoverage = [
    // simple DTO
    "com.datadog.profiling.context.PositionDecoder.*",
    "com.datadog.profiling.context.JfrTimestampPatch",
    // jacoco does not allow per-method excludes so, here we go
    "com.datadog.profiling.context.ProfilerTracingContextTrackerFactory*",
    "com.datadog.profiling.context.ProfilerTracingContextTracker.TimeTicksProvider*",
    "com.datadog.profiling.context.StatsDAccessor"
  ]
}

sourceSets {
  "main_java11" {
    java.srcDirs "${project.projectDir}/src/main/java11"
  }
}

dependencies {
  api project(':internal-api')

  implementation deps.slf4j
  main_java11CompileOnly deps.slf4j
  implementation sourceSets.main_java11.output
  implementation group: 'org.jctools', name: 'jctools-core', version: '3.3.0'

  testImplementation deps.junit5
  testImplementation deps.mockito
}

sourceCompatibility = JavaVersion.VERSION_1_8
targetCompatibility = JavaVersion.VERSION_1_8

compileMain_java11Java.doFirst {
  setJavaVersion(it, 11)
  sourceCompatibility = JavaVersion.VERSION_1_8
  targetCompatibility = JavaVersion.VERSION_1_8
}

jar {
  from sourceSets.main_java11.output
}
forbiddenApisMain_java11 {
  failOnMissingClasses = false
}

idea {
  module {
    jdkName = '11'
  }
}

jmh {
  includes = [".*TimeBucketsBenchmark"]
  //  include = ['some regular expression'] // include pattern (regular expression) for benchmarks to be executed
  //  exclude = ['some regular expression'] // exclude pattern (regular expression) for benchmarks to be executed
  iterations = 4 // Number of measurement iterations to do.
  benchmarkMode = ['thrpt']
  // Benchmark mode. Available modes are: [Throughput/thrpt, AverageTime/avgt, SampleTime/sample, SingleShotTime/ss, All/all]
//  batchSize = 1
  // Batch size: number of benchmark method calls per operation. (some benchmark modes can ignore this setting)
  fork = 1 // How many times to forks a single benchmark. Use 0 to disable forking altogether
  failOnError = true // Should JMH fail immediately if any benchmark had experienced the unrecoverable error?
  forceGC = true // Should JMH force GC between iterations?
  //  jvm = 'myjvm' // Custom JVM to use when forking.
  //  jvmArgs = ['Custom JVM args to use when forking.']
  //  jvmArgsAppend = ['Custom JVM args to use when forking (append these)']
  //  jvmArgsPrepend =[ 'Custom JVM args to use when forking (prepend these)']
  //  humanOutputFile = project.file("${project.buildDir}/reports/jmh/human.txt") // human-readable output file
  //  resultsFile = project.file("${project.buildDir}/reports/jmh/results.txt") // results file
  //  operationsPerInvocation = 10 // Operations per invocation.
  //  benchmarkParameters =  [:] // Benchmark parameters.
  profilers = ['async:libPath=/tmp/libasyncProfiler.so'] // Use profilers to collect additional data. Supported profilers: [cl, comp, gc, stack, perf, perfnorm, perfasm, xperf, xperfasm, hs_cl, hs_comp, hs_gc, hs_rt, hs_thr]
  timeOnIteration = '10s' // Time to spend at each measurement iteration.
  //  resultFormat = 'CSV' // Result format type (one of CSV, JSON, NONE, SCSV, TEXT)
  //  synchronizeIterations = false // Synchronize iterations?
  //  threads = 2 // Number of worker threads to run with.
  //  threadGroups = [2,3,4] //Override thread group distribution for asymmetric benchmarks.
  //  timeout = '1s' // Timeout for benchmark iteration.
  timeUnit = 's' // Output time unit. Available time units are: [m, s, ms, us, ns].
  //  verbosity = 'NORMAL' // Verbosity mode. Available modes are: [SILENT, NORMAL, EXTRA]
  warmup = '10s' // Time to spend at each warmup iteration.
  //  warmupBatchSize = 10 // Warmup batch size: number of benchmark method calls per operation.
  warmupForks = 1 // How many warmup forks to make for a single benchmark. 0 to disable warmup forks.
  warmupIterations = 4 // Number of warmup iterations to do.
  //  warmupMode = 'INDI' // Warmup mode for warming up selected benchmarks. Warmup modes are: [INDI, BULK, BULK_INDI].
  //  warmupBenchmarks = ['.*Warmup'] // Warmup benchmarks to include in the run in addition to already selected. JMH will not measure these benchmarks, but only use them for the warmup.

  //  zip64 = true // Use ZIP64 format for bigger archives
  jmhVersion = '1.35' // Specifies JMH version
  //  includeTests = true // Allows to include test sources into generate JMH jar, i.e. use it when benchmarks depend on the test classes.
  //duplicateClassesStrategy = 'warn'
  // Strategy to apply when encountring duplicate classes during creation of the fat jar (i.e. while executing jmhJar task)
}
